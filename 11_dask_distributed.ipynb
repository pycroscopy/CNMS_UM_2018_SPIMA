{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***USID and Dask.distributed***\n",
    "\n",
    "Emily Costa, Suhas Somnath\n",
    "\n",
    "7/30/19\n",
    "\n",
    "This document will demonstrate how Dask.distributed can be used with USID files managed with pyUSID. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import, unicode_literals\n",
    "\n",
    "# The package for accessing files in directories, etc.:\n",
    "import os\n",
    "\n",
    "# Warning package in case something goes wrong\n",
    "from warnings import warn\n",
    "import subprocess\n",
    "#from dask.diagnostics import Profiler, ResourceProfiler, visualize\n",
    "import dask.array as da\n",
    "\n",
    "\n",
    "def install(package):\n",
    "    subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "# Package for downloading online files:\n",
    "try:\n",
    "    # This package is not part of anaconda and may need to be installed.\n",
    "    import wget\n",
    "except ImportError:\n",
    "    warn('wget not found.  Will install with pip.')\n",
    "    import pip\n",
    "    install(wget)\n",
    "    import wget\n",
    "\n",
    "# The mathematical computation package:\n",
    "import numpy as np\n",
    "import dask\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import dask.array as da\n",
    "\n",
    "# The package used for creating and manipulating HDF5 files:\n",
    "import h5py\n",
    "\n",
    "# Packages for plotting:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parallel computation library:\n",
    "try:\n",
    "    import joblib\n",
    "except ImportError:\n",
    "    warn('joblib not found.  Will install with pip.')\n",
    "    import pip\n",
    "    install('joblib')\n",
    "    import joblib\n",
    "\n",
    "# Timing\n",
    "import time\n",
    "\n",
    "# A handy python utility that allows us to preconfigure parts of a function\n",
    "from functools import partial\n",
    "\n",
    "# Finally import pyUSID:\n",
    "try:\n",
    "    import pyUSID as usid\n",
    "except ImportError:\n",
    "    warn('pyUSID not found.  Will install with pip.')\n",
    "    import pip\n",
    "    install('pyUSID')\n",
    "    import pyUSID as usid\n",
    "    \n",
    "\n",
    "# import the scientific function:\n",
    "import sys\n",
    "sys.path.append('./supporting_docs/')\n",
    "from peak_finding import find_all_peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find main dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/pycroscopy/pyUSID/master/data/BELine_0004.h5'\n",
    "h5_path = 'temp.h5'\n",
    "if os.path.exists(h5_path):\n",
    "    os.remove(h5_path)\n",
    "_ = wget.download(url, h5_path, bar=None)\n",
    "    # Open the file in read-only mode\n",
    "h5_file = h5py.File(h5_path, mode='r')\n",
    "    # Get handle to the the raw data\n",
    "h5_meas_grp = h5_file['Measurement_000']\n",
    "    # Accessing the dataset of interest:\n",
    "h5_main = usid.USIDataset(h5_meas_grp['Channel_000/Raw_Data'])\n",
    "num_rows, num_cols = h5_main.pos_dim_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the find_all_peaks function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_ind, col_ind = 110, 25\n",
    "pixel_ind = col_ind + row_ind * num_cols\n",
    "spectra = h5_main[pixel_ind]\n",
    "\n",
    "peak_inds = find_all_peaks(spectra, [20, 60], num_steps=30)\n",
    "    \n",
    "fig, axis = plt.subplots()\n",
    "axis.scatter(np.arange(len(spectra)), np.abs(spectra), c='black')\n",
    "axis.axvline(peak_inds[0], color='r', linewidth=2)\n",
    "axis.set_ylim([0, 1.1 * np.max(np.abs(spectra))]);\n",
    "axis.set_title('find_all_peaks found peaks at index: {}'.format(peak_inds), fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell demonstrates the ineffectiveness of serial computation in this example.\n",
    "Compute serially:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "raw_data = h5_main[()]\n",
    "serial_results = list()\n",
    "for vector in raw_data:\n",
    "    serial_results.append(find_all_peaks(vector, [20, 60], num_steps=30))\n",
    "time_serial = time.time()-start\n",
    "core_serial = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Compute using pyUSID parallel_compute() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "raw_data = h5_main[()]\n",
    "args = [[20, 60]]\n",
    "kwargs = {'num_steps': 30}\n",
    "cores = 3\n",
    "parallel_results = usid.parallel_compute(raw_data, find_all_peaks, cores=cores, \n",
    "                                         func_args=args, func_kwargs=kwargs)\n",
    "time_parallel = time.time() - start\n",
    "cores_parallel = cores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute using Dask to automate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "raw_data = h5_main[()]\n",
    "### Do not convert numpy array to dask array for computation:\n",
    "# dask_raw_data = da.from_array(raw_data, chunks='auto')\n",
    "client = Client(processes=False)\n",
    "L = client.map(find_all_peaks, raw_data, width_bounds = [20, 60], num_steps=30)\n",
    "dask_results = client.gather(L)\n",
    "cores_dask = client.ncores()\n",
    "client.close()\n",
    "time_dask = time.time() - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(figsize=(3.5, 3.5))\n",
    "axis.scatter(core_serial, time_serial, c='blue')\n",
    "axis.scatter(cores_parallel, time_parallel, c='green')\n",
    "axis.scatter(cores_dask, time_dask, c='red')\n",
    "axis.set_xlabel('CPU cores', fontsize=14)\n",
    "axis.set_ylabel('Compute time (sec)', fontsize=14)\n",
    "plt.legend()\n",
    "fig.tight_layout()\n",
    "plt.savefig('{}.png'.format(png_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
